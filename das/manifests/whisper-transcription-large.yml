kind: Job
apiVersion: batch/v1
metadata:
  name: whisper-transcription-large-{{.JobName}}-{{.Iteration}}
  labels:
    group: whisper-large
spec:
  parallelism: 1
  completions: 1
  completionMode: Indexed
  ttlSecondsAfterFinished: 0
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: whisper-transcriber
        image: quay.io/smalleni/whisper:latest
        imagePullPolicy: Always
        command: ["/bin/sh", "-c"]
        args:
        - |
          echo "Running download script..."
          /scripts/download-audio.sh
          FILE=$(ls /data/* | head -n 1)
          echo "Running whisper transcription..."
          whisper "$FILE" --model_dir /tmp/whisper_models --model large --output_dir /tmp
        env:
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: github-token
              key: token
        - name: ITERATION
          value: "{{.Iteration}}"
        - name: BASE_INDEX
          value: "50"
        resources:
          requests:
            cpu: "4"
            memory: "12Gi"
          limits:
            memory: "12Gi"
{{ if .das }}
            nvidia.com/mig-3g.20gb: 1
{{ else }}
            nvidia.com/gpu: 1
{{ end}}
        volumeMounts:
        - name: audio-data
          mountPath: /data
        - name: model-cache-volume
          mountPath: /tmp/whisper_models
        - name: download-script
          mountPath: /scripts
      volumes:
      - name: audio-data
        emptyDir: {}
      - name: model-cache-volume
        emptyDir: {}
      - name: download-script
        configMap:
          name: audio-download-script
          defaultMode: 0755
